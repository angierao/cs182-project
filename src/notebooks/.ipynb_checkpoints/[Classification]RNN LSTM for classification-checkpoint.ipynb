{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: dlopen(/Users/demiguo/.theano/compiledir_Darwin-13.4.0-x86_64-i386-64bit-i386-2.7.12-64/cuda_ndarray/cuda_ndarray.so, 2): Symbol not found: _OSAtomicDecrement32Barrier\n",
      "  Referenced from: /usr/local/cuda/lib/libcublas.8.0.dylib\n",
      "  Expected in: /usr/lib/libSystem.B.dylib\n",
      " in /usr/local/cuda/lib/libcublas.8.0.dylib\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "import random\n",
    "import keras\n",
    "\n",
    "filename = \"../../data/labled_data.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "# [char_to_int[char] for char in str]\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "with open(filename) as f:\n",
    "    for line in f:\n",
    "        s_len = len(line)\n",
    "        block = 75\n",
    "        cur = 0\n",
    "        while (cur < s_len - 3):\n",
    "            if (cur + block < s_len - 3):\n",
    "                # only do 500 for now\n",
    "                data.append(line[cur:cur+block].lower())\n",
    "                labels.append(line[-2])\n",
    "                cur += block\n",
    "            else:\n",
    "                data.append(line[cur:-3].lower())\n",
    "                labels.append(line[-2])\n",
    "                cur = s_len - 3\n",
    " \n",
    "# Now, let's clean punctuations \n",
    "for i, sentence in enumerate(data):\n",
    "    for char in \".,&%?'\":\n",
    "        data[i] = data[i].replace(char, ' ')\n",
    "n = len(data)  # data size\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i in range(n):\n",
    "    word_vec = [char_to_int[char] for char in data[i]]\n",
    "    label = labels[i]\n",
    "    if random.randint(1,4) <= 3:\n",
    "        # train\n",
    "        X_train.append(word_vec)\n",
    "        y_train.append(label)\n",
    "    else:\n",
    "        # test\n",
    "        X_test.append(word_vec)\n",
    "        y_test.append(label)\n",
    "\n",
    "# we now pad data\n",
    "max_speech_length = max([len(sentence) for sentence in data])\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_speech_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_speech_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0 37 44 52  1 30 47 34  1 54 44 50  1  1 33 44 43 30 41 33  1]\n",
      "how are you  donald \n",
      "75\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print X_train[0]\n",
    "print data[0]\n",
    "print max_speech_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3474\n",
      "3474\n",
      "10535\n",
      "14009\n"
     ]
    }
   ],
   "source": [
    "print len(X_test)\n",
    "print len(y_test)\n",
    "print len(X_train)\n",
    "print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 75, 32)        448288      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 75, 32)        3104        embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 37, 32)        0           convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 100)           53200       maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             101         lstm_1[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 504693\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "10535/10535 [==============================] - 16s - loss: 0.4342 - acc: 0.7997    \n",
      "Epoch 2/30\n",
      "10535/10535 [==============================] - 16s - loss: 0.3975 - acc: 0.8087    \n",
      "Epoch 3/30\n",
      "10535/10535 [==============================] - 16s - loss: 0.3865 - acc: 0.8084    \n",
      "Epoch 4/30\n",
      "10535/10535 [==============================] - 16s - loss: 0.3802 - acc: 0.8124    \n",
      "Epoch 5/30\n",
      "10535/10535 [==============================] - 16s - loss: 0.3747 - acc: 0.8204    \n",
      "Epoch 6/30\n",
      "10535/10535 [==============================] - 16s - loss: 0.3605 - acc: 0.8238    \n",
      "Epoch 7/30\n",
      "10535/10535 [==============================] - 16s - loss: 0.3505 - acc: 0.8281    \n",
      "Epoch 8/30\n",
      "10535/10535 [==============================] - 18s - loss: 0.3420 - acc: 0.8376    \n",
      "Epoch 9/30\n",
      "10535/10535 [==============================] - 17s - loss: 0.3347 - acc: 0.8421    \n",
      "Epoch 10/30\n",
      "10535/10535 [==============================] - 19s - loss: 0.3214 - acc: 0.8497    \n",
      "Epoch 11/30\n",
      "10535/10535 [==============================] - 15s - loss: 0.3155 - acc: 0.8548    \n",
      "Epoch 12/30\n",
      "10535/10535 [==============================] - 15s - loss: 0.3093 - acc: 0.8569    \n",
      "Epoch 13/30\n",
      "10535/10535 [==============================] - 16s - loss: 0.3078 - acc: 0.8586    \n",
      "Epoch 14/30\n",
      "10535/10535 [==============================] - 16s - loss: 0.3012 - acc: 0.8629    \n",
      "Epoch 15/30\n",
      "10535/10535 [==============================] - 15s - loss: 0.2933 - acc: 0.8649    \n",
      "Epoch 16/30\n",
      "10535/10535 [==============================] - 15s - loss: 0.2933 - acc: 0.8712    \n",
      "Epoch 17/30\n",
      "10535/10535 [==============================] - 15s - loss: 0.2818 - acc: 0.8732    \n",
      "Epoch 18/30\n",
      "10535/10535 [==============================] - 15s - loss: 0.2821 - acc: 0.8744    \n",
      "Epoch 19/30\n",
      "10535/10535 [==============================] - 16s - loss: 0.2812 - acc: 0.8730    \n",
      "Epoch 20/30\n",
      "10535/10535 [==============================] - 16s - loss: 0.2698 - acc: 0.8779    \n",
      "Epoch 21/30\n",
      "10535/10535 [==============================] - 17s - loss: 0.2655 - acc: 0.8815    \n",
      "Epoch 22/30\n",
      "10535/10535 [==============================] - 17s - loss: 0.2619 - acc: 0.8832    \n",
      "Epoch 23/30\n",
      "10535/10535 [==============================] - 17s - loss: 0.2576 - acc: 0.8858    \n",
      "Epoch 24/30\n",
      "10535/10535 [==============================] - 18s - loss: 0.2522 - acc: 0.8880    \n",
      "Epoch 25/30\n",
      "10535/10535 [==============================] - 20s - loss: 0.2486 - acc: 0.8924    \n",
      "Epoch 26/30\n",
      "10535/10535 [==============================] - 22s - loss: 0.2471 - acc: 0.8925    \n",
      "Epoch 27/30\n",
      "10535/10535 [==============================] - 18s - loss: 0.2418 - acc: 0.8954    \n",
      "Epoch 28/30\n",
      "10535/10535 [==============================] - 18s - loss: 0.2444 - acc: 0.8952    \n",
      "Epoch 29/30\n",
      "10535/10535 [==============================] - 18s - loss: 0.2305 - acc: 0.9012    \n",
      "Epoch 30/30\n",
      "10535/10535 [==============================] - 19s - loss: 0.2296 - acc: 0.9005    \n",
      "Accuracy: 86.36%\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(n, embedding_vecor_length, input_length=max_speech_length))\n",
    "model.add(Convolution1D(nb_filter=32, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, nb_epoch=30, batch_size=100)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
