{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn import ensemble\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import StringIO\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data_filename = \"../../data/labeled_data.txt\"\n",
    "max_sentence_length = 1000  # ignore\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "with open(data_filename) as f:\n",
    "    for line in f:\n",
    "        s_len = len(line)\n",
    "        cur = 0\n",
    "        # split to segments of maximal length of max_sentence_length\n",
    "        while (cur < s_len - 3):\n",
    "            if (cur + max_sentence_length < s_len - 3):\n",
    "                data.append(line[cur:cur+max_sentence_length].lower())\n",
    "                labels.append(int(line[-2]))\n",
    "                cur += max_sentence_length\n",
    "            else:\n",
    "                data.append(line[cur:-3].lower())\n",
    "                labels.append(int(line[-2]))\n",
    "                cur = s_len - 3\n",
    "\n",
    "# Now, let's clean punctuations \n",
    "for i, sentence in enumerate(data):\n",
    "    for char in \".,&%?'\":\n",
    "        data[i] = data[i].replace(char, ' ')\n",
    "        \n",
    "n = len(data)\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in range(n):\n",
    "    if random.randint(1, 8) <= 6:\n",
    "        x_train.append(data[i])\n",
    "        y_train.append(labels[i])\n",
    "    else:\n",
    "        x_test.append(data[i])\n",
    "        y_test.append(labels[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(encoding='latin1', stop_words=['and', 'or', 'before', 'a', 'an', 'am', 'the', 'at', 'by', 'br'], min_df=4)\n",
    "x = vectorizer.fit_transform(x_train)\n",
    "x = x.toarray()\n",
    "print type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts = zip(x_train, x)\n",
    "num_words = len(word_counts)\n",
    "m = 12  # number of features\n",
    "n = len(x)\n",
    "vocab = vectorizer.vocabulary_.items()\n",
    "vocab = sorted(vocab, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentence_length(text):\n",
    "    return len(text)\n",
    "\n",
    "def average_word_length(words):\n",
    "    return sum([len(word) for word in words]) / float(len(words))\n",
    "    \n",
    "def max_repeat(words):\n",
    "    word_count = {}\n",
    "    for word in words:\n",
    "        if word not in word_count:\n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1\n",
    "\n",
    "    return max(word_count.values())\n",
    "        \n",
    "def number_of_repeated_words(words):\n",
    "    word_count = {}\n",
    "    for word in words:\n",
    "        if word not in word_count:\n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1\n",
    "    return sum([1 for word in word_count if word_count[word] > 1])\n",
    "\n",
    "def contain_great(words):\n",
    "    return int(\"great\" in words)\n",
    "\n",
    "def contain_people(words):\n",
    "    return int(\"people\" in words)\n",
    "\n",
    "def contain_country(words):\n",
    "    return int(\"country\" in words)\n",
    "\n",
    "def contain_we(words):\n",
    "    return int(\"we\" in words)\n",
    "\n",
    "def contain_you(words):\n",
    "    return int(\"you\" in words)\n",
    "\n",
    "def contain_them(words):\n",
    "    return int(\"them\" in words)\n",
    "\n",
    "def contain_job(words):\n",
    "    return int(\"job\" in words)\n",
    "\n",
    "def contain_I(words):\n",
    "    return int(\"i\" in words)\n",
    "\n",
    "# calc_features\n",
    "def calc_features(text):\n",
    "    if text[-1] == '.':  # delete end punctuation\n",
    "        text = text[:-1]\n",
    "    words = text.split(' ')\n",
    "    words = [word.lower() for word in words]\n",
    "    return [sentence_length(text), average_word_length(words),\\\n",
    "           max_repeat(words), number_of_repeated_words(words),\\\n",
    "           contain_great(words), contain_people(words),\\\n",
    "           contain_country(words), contain_we(words), contain_you(words), contain_them(words),\\\n",
    "           contain_job(words), contain_I(words)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38, 4.571428571428571, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# testing purpose\n",
    "print calc_features(\"happy happy. happy ... birthday to you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data = []\n",
    "\n",
    "def getFeaturesFromData():\n",
    "    global n\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        data.append((y_train[i], calc_features(x_train[i])))\n",
    "            \n",
    "getFeaturesFromData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def getMean(arr):\n",
    "    return sum(arr) / float(len(arr))\n",
    "\n",
    "def getStdev(arr):\n",
    "    avg = getMean(arr)\n",
    "    variance = sum([pow(x-avg, 2) for x in arr])/float(len(arr)-1)\n",
    "    return math.sqrt(variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means = []\n",
    "stdevs = []\n",
    "def processData():\n",
    "    global means\n",
    "    global stdevs\n",
    "    means = [[], []]\n",
    "    stdevs = [[], []]\n",
    "    for label in range(2):\n",
    "        for f in range(m):\n",
    "            arr = [entry[1][f] for entry in data if entry[0] == label]\n",
    "            means[label].append(getMean(arr))\n",
    "            stdevs[label].append(getStdev(arr))\n",
    "processData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def mylog(x):\n",
    "    if x == 0:\n",
    "        return sys.float_info.min\n",
    "    else:\n",
    "        return math.log(x)\n",
    "\n",
    "def calculateProbability(x, mean, stdev):\n",
    "    if stdev < sys.float_info.epsilon:\n",
    "        return sys.float_info.max\n",
    "    else: \n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev, 2))))\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predictData(text):\n",
    "    inputFeatures = calc_features(text)\n",
    "    ans = [0] * 2\n",
    "    total = [0] * 2\n",
    "    for i in range(n):\n",
    "        total[data[i][0]] += 1\n",
    "    for label in range(2): \n",
    "       ans[label] += mylog(total[label] / (1.0 * total[0] + total[1]))\n",
    "       for i in range(m):\n",
    "           ans[label] += mylog(calculateProbability(inputFeatures[i], means[label][i], stdevs[label][i]))\n",
    "    if ans[0] > ans[1]:\n",
    "        return (0, \"Donald Trump\")\n",
    "    else:\n",
    "        return (1, \"Hillary Clinton\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testData(test_data):\n",
    "    num_correct = 0\n",
    "    num_total = len(test_data)\n",
    "    for test_entry in test_data:\n",
    "        num_correct += predictData(test_entry[1])[0] == test_entry[0]\n",
    "    print \"CORRECT \", num_correct, \" out of \", num_total,\\\n",
    "            \" percentage = %.2f\" % (float(num_correct) / num_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = zip(y_test, x_test)\n",
    "testData(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
